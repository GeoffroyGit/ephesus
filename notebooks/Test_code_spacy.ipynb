{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37122ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9485b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephesus.sentence import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a68bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_json(\"PROJECT_EPHESUS-labeling_V02.json\")\n",
    "dico = tune_data(data)\n",
    "train_set, test_set = create_training_set(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f515938f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 360/360 [00:03<00:00, 117.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data created under '../raw_data/train_test_02.spacy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_training_data(train_set, \"train_test_02.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_model(\"../models/model_small/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d175e303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Pour monsieur Didier Nicolas le \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3 mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Date</span>\n",
       "</mark>\n",
       ", un \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    vaccin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Treatment</span>\n",
       "</mark>\n",
       " donc 2 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ami1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Cotation</span>\n",
       "</mark>\n",
       " pour sylvie, merci.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = test_set[\"annotations\"][5]['text']\n",
    "doc = nlp(test)\n",
    "spacy.displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aeff1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 202.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data created under '../raw_data/test_set_02.spacy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_training_data(test_set, \"test_set_02.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dea77f",
   "metadata": {},
   "source": [
    "Test de return_label vs. original labelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e281d6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m return_label(\u001b[43msentence\u001b[49m,nlp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "return_label(sentence,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a60573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_set[\"annotations\"])\n",
    "liste_test = df_test.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df_test.iloc[0,0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8e3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for elm in liste_test:\n",
    "    print(sentence[elm[0]:elm[1]])\n",
    "    print(elm[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9023cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sentence, ents):\n",
    "    liste = []\n",
    "    for elm in ents:\n",
    "        \n",
    "        liste.append((sentence[elm[0]:elm[1]],elm[2]))\n",
    "    return liste\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfa051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test(sentence,liste_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data(test_set, \"test_set.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e88b7c",
   "metadata": {},
   "source": [
    "# Tuto from https://www.kaggle.com/code/finalepoch/medical-ner-using-spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import random\n",
    "from pathlib import Path\n",
    "from spacy.util import minibatch, compounding\n",
    "import spacy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06af2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec417172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model=None, output_dir=\"../models/test_model\", n_iter=1000):\n",
    "    \n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)\n",
    "        print(\"Loaded model '%s'\" %model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"fr\")\n",
    "        print(\"Created blank 'fr' model\")\n",
    "        \n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe('ner')\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(dico[\"annotations\"])\n",
    "            losses = {}\n",
    "            batches = minibatch(dico[\"annotations\"], size=compounding(4.0, 64.0, 1.2))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  \n",
    "                    annotations,  \n",
    "                    drop=0.20, \n",
    "                    losses=losses\n",
    "                   \n",
    "                )\n",
    "            print(\"Losses\", losses)\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ef351",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_model(\"../models/model_small/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = dico[\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.training import Example\n",
    "\n",
    "nlp = spacy.blank(\"fr\")\n",
    "nlp.add_pipe('ner')\n",
    "nlp.begin_training()\n",
    "# TRAINING THE MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = TRAIN_DATA[0][\"text\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = TRAIN_DATA[1]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Example.from_dict(nlp.make_doc(text), annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2967cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.update([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be509b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc21a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e20181",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'entities':TRAIN_DATA[1]['entities']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6be2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"fr\")\n",
    "nlp.add_pipe('ner')\n",
    "nlp.begin_training()\n",
    "# TRAINING THE MODEL\n",
    "\n",
    "example = []\n",
    "i= 0\n",
    "for elm in TRAIN_DATA:\n",
    "    example = Example.from_dict(nlp.make_doc(elm['text']),{'entities':elm['entities']})\n",
    "    nlp.update([example], drop=0.5)\n",
    "    print(\"Losses\", losses)\n",
    "    print(i)\n",
    "    i += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09328f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Sous-cutanée débuté le 3 septembre, 2 fois par jour. Jusqu'au. 8 septembre.\")\n",
    "spacy.displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfbe42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
